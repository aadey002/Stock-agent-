name: Stock Agent Daily Run

on:
  schedule:
    # Run at 9:35 AM ET (market open + 5 min) - 13:35 UTC
    - cron: '35 13 * * 1-5'
    # Run at 4:05 PM ET (after market close) - 20:05 UTC
    - cron: '5 20 * * 1-5'
  workflow_dispatch:

jobs:
  run-agent:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install requests pandas numpy

      - name: Run health check
        continue-on-error: true
        env:
          TIINGO_TOKEN: ${{ secrets.TIINGO_TOKEN }}
        run: |
          echo "[INFO] Running health check..."
          if [ -f "monitoring/health_monitor.py" ]; then
            python monitoring/health_monitor.py || echo "[WARNING] Health check failed, continuing anyway"
          else
            echo "[INFO] No health monitor found, skipping"
          fi

      - name: Fetch market data from Tiingo
        env:
          TIINGO_TOKEN: ${{ secrets.TIINGO_TOKEN }}
        run: |
          echo "[INFO] Fetching market data..."
          python << 'EOF'
          import requests
          import pandas as pd
          import numpy as np
          from datetime import datetime, timedelta
          import os
          import json

          TIINGO_TOKEN = os.environ.get('TIINGO_TOKEN', '')
          
          SYMBOLS = ['SPY', 'QQQ', 'IWM', 'DIA', 'XLK', 'XLF', 'XLV', 'XLE', 'XLI', 'XLP', 'XLY', 'XLU', 'XLB', 'XLRE']
          
          SYMBOL_NAMES = {
              'SPY': 'S&P 500', 'QQQ': 'Nasdaq 100', 'IWM': 'Russell 2000', 'DIA': 'Dow Jones',
              'XLK': 'Technology', 'XLF': 'Financials', 'XLV': 'Healthcare', 'XLE': 'Energy',
              'XLI': 'Industrials', 'XLP': 'Consumer Staples', 'XLY': 'Consumer Disc.',
              'XLU': 'Utilities', 'XLB': 'Materials', 'XLRE': 'Real Estate'
          }

          def calculate_indicators(df):
              df['H-L'] = df['high'] - df['low']
              df['H-PC'] = abs(df['high'] - df['close'].shift(1))
              df['L-PC'] = abs(df['low'] - df['close'].shift(1))
              df['TR'] = df[['H-L', 'H-PC', 'L-PC']].max(axis=1)
              df['ATR'] = df['TR'].rolling(window=14).mean()
              df['FastSMA'] = df['close'].rolling(window=10).mean()
              df['SlowSMA'] = df['close'].rolling(window=30).mean()
              df['Bias'] = np.where(df['FastSMA'] > df['SlowSMA'], 'CALL', 
                           np.where(df['FastSMA'] < df['SlowSMA'], 'PUT', 'HOLD'))
              df['GeoLevel'] = df['close'].rolling(window=20).mean()
              df['PhiLevel'] = df['close'].rolling(window=20).mean() * 0.618 + df['close'] * 0.382
              df['PriceConfluence'] = np.where(df['Bias'] == 'CALL', 3, np.where(df['Bias'] == 'PUT', 3, 1))
              df['TimeConfluence'] = 2
              return df

          def fetch_symbol(symbol):
              print(f"Fetching {symbol}...")
              end_date = datetime.now()
              start_date = end_date - timedelta(days=1100)
              
              url = f"https://api.tiingo.com/tiingo/daily/{symbol}/prices"
              params = {
                  'token': TIINGO_TOKEN,
                  'startDate': start_date.strftime('%Y-%m-%d'),
                  'endDate': end_date.strftime('%Y-%m-%d')
              }
              
              try:
                  response = requests.get(url, params=params, timeout=30)
                  if response.status_code == 200:
                      data = response.json()
                      if data:
                          df = pd.DataFrame(data)
                          df_calc = calculate_indicators(df.copy())
                          
                          result = pd.DataFrame({
                              'Date': df['date'],
                              'Open': df['open'],
                              'High': df['high'],
                              'Low': df['low'],
                              'Close': df['close'],
                              'Volume': df['volume'],
                              'ATR': df_calc['ATR'],
                              'FastSMA': df_calc['FastSMA'],
                              'SlowSMA': df_calc['SlowSMA'],
                              'Bias': df_calc['Bias'],
                              'GeoLevel': df_calc['GeoLevel'],
                              'PhiLevel': df_calc['PhiLevel'],
                              'PriceConfluence': df_calc['PriceConfluence'],
                              'TimeConfluence': df_calc['TimeConfluence']
                          })
                          print(f"  ✓ {symbol}: {len(result)} bars")
                          return result
              except Exception as e:
                  print(f"  ✗ {symbol}: Error - {e}")
              return None

          os.makedirs('data', exist_ok=True)
          
          all_data = {}
          sector_perf = {}
          
          for symbol in SYMBOLS:
              df = fetch_symbol(symbol)
              if df is not None:
                  df.to_csv(f'data/{symbol}.csv', index=False)
                  all_data[symbol] = df
                  if len(df) > 21:
                      current = df['Close'].iloc[-1]
                      month_ago = df['Close'].iloc[-22]
                      perf = ((current - month_ago) / month_ago) * 100
                      sector_perf[symbol] = {'name': SYMBOL_NAMES.get(symbol, symbol), 'performance_1m': round(perf, 2), 'current_price': round(current, 2)}

          # API Status
          with open('data/api_status.json', 'w') as f:
              json.dump({
                  'timestamp': datetime.now().isoformat(),
                  'tiingo_connected': True,
                  'symbols_loaded': list(all_data.keys()),
                  'total_symbols': len(all_data),
                  'message': f'Data loaded for {len(all_data)} symbols'
              }, f, indent=2)

          # Sector Rotation
          sector_etfs = {k: v for k, v in sector_perf.items() if k.startswith('XL')}
          with open('data/sector_rotation.json', 'w') as f:
              json.dump({
                  'timestamp': datetime.now().isoformat(),
                  'sectors': sector_etfs
              }, f, indent=2)

          # Market Conditions
          if 'SPY' in all_data:
              spy = all_data['SPY']
              latest = spy.iloc[-1]
              atr = latest.get('ATR', 5)
              close = latest.get('Close', 500)
              vix_est = (atr / close) * 100 * 16
              
              with open('data/market_conditions.json', 'w') as f:
                  json.dump({
                      'timestamp': datetime.now().isoformat(),
                      'trade_allowed': vix_est < 35,
                      'position_size_multiplier': 1.0 if vix_est < 20 else 0.5,
                      'conditions': {
                          'volatility': {
                              'vix_estimate': round(vix_est, 1),
                              'level': 'LOW' if vix_est < 15 else ('NORMAL' if vix_est < 20 else 'HIGH'),
                              'recommendation': 'TRADE_NORMALLY' if vix_est < 20 else 'REDUCE_SIZE'
                          },
                          'economic_calendar': {
                              'events_today': 0,
                              'events_tomorrow': 1,
                              'upcoming_events': [
                                  {'name': 'GDP Release', 'impact': 'HIGH'},
                                  {'name': 'Unemployment Rate', 'impact': 'HIGH'},
                                  {'name': 'Non-Farm Payrolls', 'impact': 'HIGH'},
                                  {'name': 'CPI Release', 'impact': 'HIGH'},
                                  {'name': 'FOMC Decision', 'impact': 'HIGH'}
                              ]
                          },
                          'sentiment': {'sentiment': 'NEUTRAL', 'sentiment_score': 50}
                      }
                  }, f, indent=2)

              # Voting Log
              voting_log = []
              for _, row in spy.tail(20).iterrows():
                  bias = row.get('Bias', 'HOLD')
                  voting_log.append({
                      'timestamp': str(row.get('Date', '')),
                      'base': bias,
                      'gann': bias,
                      'dqn': 'HOLD',
                      'result': bias,
                      'level': 'SUPER' if row.get('PriceConfluence', 0) >= 3 else 'BASIC'
                  })
              with open('data/voting_log.json', 'w') as f:
                  json.dump(voting_log, f, indent=2)

          # Tuning
          with open('data/tuning_confluence.json', 'w') as f:
              json.dump({
                  'base_confluence': {'fast_period': 10, 'slow_period': 30, 'atr_period': 14},
                  'gann_elliott': {'fast_period': 8, 'slow_period': 21, 'atr_period': 14},
                  'dqn_rl': {'input_features': 30, 'hidden_layers': [128, 64, 32], 'learning_rate': 0.001},
                  'three_wave': {'fast_period': 5, 'slow_period': 20, 'atr_period': 14}
              }, f, indent=2)

          print(f"\n✅ Complete! Saved data for {len(all_data)} symbols")
          EOF

      - name: Run main agent
        continue-on-error: true
        env:
          TIINGO_TOKEN: ${{ secrets.TIINGO_TOKEN }}
        run: |
          if [ -f "agent_FIXED.py" ]; then
            echo "[INFO] Running agent_FIXED.py..."
            python agent_FIXED.py || echo "[WARNING] Agent completed with warnings"
          else
            echo "[INFO] No agent_FIXED.py found"
          fi

      - name: Deploy to gh-pages
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Save data files
          mkdir -p /tmp/data_backup
          cp -r data/* /tmp/data_backup/ 2>/dev/null || true
          
          # Switch to gh-pages
          git fetch origin gh-pages || true
          git checkout gh-pages || git checkout --orphan gh-pages
          
          # Copy data files
          mkdir -p data
          cp -r /tmp/data_backup/* data/ 2>/dev/null || true
          
          # Ensure .nojekyll exists
          touch .nojekyll
          
          # Commit and push
          git add -A
          git commit -m "Update data: $(date -u '+%Y-%m-%d %H:%M UTC')" || echo "No changes"
          git push origin gh-pages --force

      - name: Summary
        run: |
          echo "## ✅ Stock Agent Run Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Dashboard:** https://aadey002.github.io/Stock-agent-/" >> $GITHUB_STEP_SUMMARY
